# Avito Parser info:
---

## Как пользоваться:

Вызываем функцию `parse()` от:

1. Города английским транслитом. (Пример: 'moscva', 'chelyabinsk', ...) (P.S. Лучше вызвывать от города, в котором вы находитесь, от другого может не работать!!!)
2. Названия одного из разделов Авито. (Пример: 'tovary_dlya_kompyutera', 'bytovaya_elektronika', ...)

---

## Краткая информация:

- Используется юзер-агент (без него всё тоже может работать). Он нужен для свободного посещения сайта в статусе юзера, а не бота.
- Ищем по html сайта нужную информацию через библиотеку BeautifulSoup и requests.
- HTML-классы переданы в код путём анализа кода элемента страницы (F12).
- Каждое объявление помещается в список товаров словарём вида: `{ключ - название предмета/услуги: значение - цена}`.

### Сторонние подключения:

 - bs4
 - request
---

# PDD Answer Finder info:
---

## Как пользоваться:

- Добавляем в директорию с файлом программы файл `questions.txt`.
- Запускаем программу.
- Результатом данной программы является созданный/перезаписанный файл `answers.txt` в этой же директории.
   
## Краткое описание:

-Данный парсер получает от вас на вход файл `questions.txt`, в котором записаны билеты по ПДД (без лишних символов, каждый с новой строки).
-В ходе парсинга он пробегается по всем темам и билетам сайта [biletpdd.ru](https://biletpdd.ru/bilety/ab/) и добавляет в список словари вида `{вопрос билета : правильный ответ}`.
-После парсинга данные из списка попадают в цикл, где вопросы с нашего `questions.txt` по очереди сравниваются с вопросами из списка. Если вопросы совпали — записываем в файл `answers.txt` ответ на вопрос.
-Так как существуют вопросы, где текст выглядит одинаково, а картинки разные, была придумана система отступов.

---

### Пример передаваемого содержимого в `questions.txt`:

```
"Вопрос №1"
"Вопрос №2"
"Вопрос №3"
"Вопрос №4"
```

### Пример того, как может выглядеть `answers.txt` после окончания выполнения программы:

```
"Ответ на вопрос №1" (выводит ответ первого по очереди вопроса из `questions.txt`)
Нету ответов на данный вопрос. (выводится, так как второй вопрос не совпал ни с одним из всего списка)
"Ответ на вопрос №3" (выводит ответ первого по очереди вопроса из `questions.txt`)
    Найден еще один ответ: "Ответ на вопрос №3" (вывод производится с отступом и предупреждением "Найден еще один ответ: ", если на этот вопрос нашелся еще один ответ)
    Найден еще один ответ: "Ответ на вопрос №3" (вывод производится с отступом и предупреждением "Найден еще один ответ: ", если на этот вопрос нашелся еще один ответ)
"Ответ на вопрос №4" (выводит ответ первого по очереди вопроса из `questions.txt`)
```

### Сторонние подключения:

 - bs4
 - request
 - fake_useragent
 - lxml

---
# Proxy Parser info:
---

## Краткая информация:

- Парсер работает с таблицей, содержащей прокси на сайте [hidexn.name](https://hidexn.name/proxy-list/), возвращая табличные данные в двух видах (txt, csv) в директорию программы.
- proxies.txt содержит краткую выжимку типа "{ip-адрес}:{порт}".
- proxies.csv нужен для более подробного анализа. Содержит: [IP адрес; Порт;	Страна, Город;	Скорость;	Тип;	Анонимность;	Последнее обновление]
- Реализованы несколько видов вызова парсера: self.parse_csv (парсинг + генерация таблицы *.csv), parse_txt (парсинг + генерация сжатой информации о прокси в *.txt), parse_txt_csv (делает всё выше перечисленное).

### Сторонние подключения:

 - bs4
 - request
 - lxml
 - fake_useragent
 - csv

---
# STOPGAME News Parser info:
---

## Краткая информация:

- Парсер работает с разделом "Новости" сайта [stopgame.ru](https://stopgame.ru/news) собирая отчет о комментариях к новостям, возвращая данный отчет файлом типа *.json.
- Для старта программы, нужно указать количество страниц сайта, которые мы хотим спарсить. (Парсинг идет от новых к старым)

---

### Пример того, как может выглядеть `comments.json` после окончания выполнения программы:

```
{
   Заголовок_новости_1: {
      Пользователь_1: комментарий,
      Пользователь_2: комментарий,
      ...
   },
   Заголовок_новости_2: {
      Пользователь_3: комментарий,
      Пользователь_4: комментарий,
      ...
   },
   ...
}
```

### Сторонние подключения:

 - bs4
 - request
 - lxml
 - fake_useragent
 - json
---

# Youtube Tag Analyzer info:
---

## Краткая информация:

- Если вы из России - используйте различные приложения для обхода блокировки сайта.
- ~~Из-за того, что во многих регионах интерфейс сайта отличается от СНГ варианта, во время поиска выбирайте в впн страну, входящую в СНГ. (В интерфейсе ЕС, например, есть множество отличий, из за которых программа выдаст ошибку.)~~
- Upd: добавлена поддержка интерфейса других регионов.
- Парсер получает от вас поисковой запрос, который отправляет в поисковую строку сайта [youtube.com](https://www.youtube.com/), фильтруя поиск по "Видео" и "По числу просмотров".
- Парсер работает с таблицей, содержащей прокси на сайте , возвращая информацию о каждом видео в двух видах (txt, json) в директорию программы.
- youtube_tag_analyzer.txt содержит все теги со всех видео.
- youtube_tag_analyzer.json на каждое виде содержит выжимку вида: имя автора; название видео; ссылка; количество просмотров; дата; теги из этого видео.
- Вся разработка и тестирование программы проходила с использованием Chrome версии 114.0.5735.199 и ChromeDriver версии 114.0.5735.90.

### Сторонние подключения:

 - selenium
 - json
 - emoji
 - time (библиотека python)

---
